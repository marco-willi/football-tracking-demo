{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Model Variant Comparison\n",
    "\n",
    "Compare YOLO26 (n/s/m/l/x) and two legacy YOLOv8 variants (s, x) on the same broadcast footage.\n",
    "We evaluate detection quality (count, confidence distribution), inference speed,\n",
    "and visual output to pick the best speed-accuracy trade-off for player tracking.\n",
    "\n",
    "Performance reference: [Ultralytics YOLO26 docs](https://docs.ultralytics.com/models/yolo26/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrootutils\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from football_tracking_demo.config import load_config\n",
    "from football_tracking_demo.detector import PlayerDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pyrootutils.setup_root(\n",
    "    search_from=\".\",\n",
    "    indicator=\"pyproject.toml\",\n",
    "    project_root_env_var=True,\n",
    "    dotenv=True,\n",
    "    pythonpath=True,\n",
    "    cwd=True,\n",
    ")\n",
    "\n",
    "VIDEO_PATH = str(root / \"data\" / \"match.mp4\")\n",
    "CONFIG_PATH = str(root / \"config\" / \"config.yaml\")\n",
    "\n",
    "# Model variants to compare.\n",
    "# YOLO26 performance (COCO val, 640px): https://docs.ultralytics.com/models/yolo26/\n",
    "# YOLOv8 kept as legacy baseline for comparison.\n",
    "#\n",
    "# mAP and CPU/GPU figures sourced from Ultralytics official docs.\n",
    "MODEL_VARIANTS = [\n",
    "    # --- YOLO26 (recommended) ---\n",
    "    {\n",
    "        \"name\": \"yolo26n\",\n",
    "        \"file\": \"yolo26n.pt\",\n",
    "        \"params\": \"2.4M\",\n",
    "        \"flops_b\": 5.4,\n",
    "        \"map\": 40.9,\n",
    "        \"cpu_ms\": 38.9,\n",
    "        \"gpu_ms\": 1.7,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yolo26s\",\n",
    "        \"file\": \"yolo26s.pt\",\n",
    "        \"params\": \"9.5M\",\n",
    "        \"flops_b\": 20.7,\n",
    "        \"map\": 48.6,\n",
    "        \"cpu_ms\": 87.2,\n",
    "        \"gpu_ms\": 2.5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yolo26m\",\n",
    "        \"file\": \"yolo26m.pt\",\n",
    "        \"params\": \"20.4M\",\n",
    "        \"flops_b\": 68.2,\n",
    "        \"map\": 53.1,\n",
    "        \"cpu_ms\": 220.0,\n",
    "        \"gpu_ms\": 4.7,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yolo26l\",\n",
    "        \"file\": \"yolo26l.pt\",\n",
    "        \"params\": \"24.8M\",\n",
    "        \"flops_b\": 86.4,\n",
    "        \"map\": 55.0,\n",
    "        \"cpu_ms\": 286.2,\n",
    "        \"gpu_ms\": 6.2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yolo26x\",\n",
    "        \"file\": \"yolo26x.pt\",\n",
    "        \"params\": \"55.7M\",\n",
    "        \"flops_b\": 193.9,\n",
    "        \"map\": 57.5,\n",
    "        \"cpu_ms\": 525.8,\n",
    "        \"gpu_ms\": 11.8,\n",
    "    },\n",
    "    # --- YOLOv8 legacy ---\n",
    "    {\n",
    "        \"name\": \"yolov8s\",\n",
    "        \"file\": \"yolov8s.pt\",\n",
    "        \"params\": \"11.2M\",\n",
    "        \"flops_b\": 28.6,\n",
    "        \"map\": 44.9,\n",
    "        \"cpu_ms\": 128.4,\n",
    "        \"gpu_ms\": 1.2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"yolov8x\",\n",
    "        \"file\": \"yolov8x.pt\",\n",
    "        \"params\": \"68.2M\",\n",
    "        \"flops_b\": 257.8,\n",
    "        \"map\": 53.9,\n",
    "        \"cpu_ms\": 479.1,\n",
    "        \"gpu_ms\": 3.5,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Sample frames for visual comparison\n",
    "SAMPLE_FRAME_INDICES = [0, 1500, 3000, 4500, 6000]\n",
    "\n",
    "# Frames for speed & count sweep\n",
    "SWEEP_N_FRAMES = 100\n",
    "\n",
    "# Fixed confidence threshold across all models (isolate model quality)\n",
    "CONF_THRESHOLD = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config & Sample Frames\n",
    "\n",
    "Extract sample frames from the video for visual comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frames = {}\n",
    "max_idx = max(SAMPLE_FRAME_INDICES)\n",
    "\n",
    "for i in range(max_idx + 1):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if i in SAMPLE_FRAME_INDICES:\n",
    "        frames[i] = frame\n",
    "\n",
    "cap.release()\n",
    "print(f\"Loaded {len(frames)} sample frames: {sorted(frames.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Detectors for Each Model Variant\n",
    "\n",
    "Create one `PlayerDetector` per YOLO variant. All other settings (confidence, NMS, HUD mask, playing field filter) are held constant so only the backbone size varies. Weights are loaded from / cached in `checkpoints/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = {}\n",
    "for variant in MODEL_VARIANTS:\n",
    "    print(f\"Loading {variant['name']} ({variant['params']} params)...\")\n",
    "    detectors[variant[\"name\"]] = PlayerDetector(\n",
    "        model_name=variant[\"file\"],\n",
    "        model_dir=config[\"detection\"].get(\"model_dir\", \"checkpoints\"),\n",
    "        conf_threshold=CONF_THRESHOLD,\n",
    "        iou_threshold=config[\"detection\"][\"nms_iou_threshold\"],\n",
    "        device=config[\"detection\"][\"device\"],\n",
    "        hud_top=config[\"hud_mask\"][\"top_percent\"],\n",
    "        hud_bottom=config[\"hud_mask\"][\"bottom_percent\"],\n",
    "        hud_enabled=config[\"hud_mask\"][\"enabled\"],\n",
    "        shape_filter_config=config.get(\"detection_shape_filter\"),\n",
    "        field_mask_config=config.get(\"playing_field_mask\"),\n",
    "    )\n",
    "\n",
    "print(f\"\\nLoaded {len(detectors)} model variants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Comparison per Frame\n",
    "\n",
    "For each sample frame show all model variants side-by-side with bounding boxes. Larger models should produce more confident and spatially accurate detections, especially for distant / partially occluded players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dets_on_ax(ax, frame_bgr, detections, title=\"\"):\n",
    "    \"\"\"Draw detection boxes on a matplotlib axis.\"\"\"\n",
    "    rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    _ = ax.imshow(rgb)\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2, conf = det\n",
    "        rect = Rectangle(\n",
    "            (x1, y1),\n",
    "            x2 - x1,\n",
    "            y2 - y1,\n",
    "            linewidth=1.5,\n",
    "            edgecolor=\"lime\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        _ = ax.add_patch(rect)\n",
    "        _ = ax.text(\n",
    "            x1,\n",
    "            y1 - 3,\n",
    "            f\"{conf:.2f}\",\n",
    "            color=\"lime\",\n",
    "            fontsize=6,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.15\", facecolor=\"black\", alpha=0.6),\n",
    "        )\n",
    "    _ = ax.set_title(title, fontsize=10)\n",
    "    _ = ax.set_axis_off()\n",
    "\n",
    "\n",
    "variant_names = [v[\"name\"] for v in MODEL_VARIANTS]\n",
    "\n",
    "for idx, frame in sorted(frames.items()):\n",
    "    n = len(variant_names)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(5 * n, 5))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, name in zip(axes, variant_names):\n",
    "        dets = detectors[name].detect_and_filter(frame)\n",
    "        draw_dets_on_ax(ax, frame, dets, title=f\"{name}  ({len(dets)} dets)\")\n",
    "\n",
    "    fig.suptitle(f\"Frame {idx}  —  conf={CONF_THRESHOLD}\", fontsize=13, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Speed Benchmark\n",
    "\n",
    "Time each model over N frames and report mean / std inference time per frame. This includes HUD masking, YOLO forward pass, NMS, and playing field filtering — the full `detect_and_filter` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_results = {name: [] for name in variant_names}\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "bench_frames = []\n",
    "for i in range(SWEEP_N_FRAMES):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    bench_frames.append(frame)\n",
    "cap.release()\n",
    "\n",
    "print(f\"Benchmarking {len(bench_frames)} frames per model...\\n\")\n",
    "\n",
    "for name in variant_names:\n",
    "    det = detectors[name]\n",
    "    # Warm-up pass (first inference is slower due to model init)\n",
    "    _ = det.detect_and_filter(bench_frames[0])\n",
    "\n",
    "    times = []\n",
    "    for frame in bench_frames:\n",
    "        t0 = time.perf_counter()\n",
    "        _ = det.detect_and_filter(frame)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append((t1 - t0) * 1000)  # ms\n",
    "\n",
    "    speed_results[name] = times\n",
    "    arr = np.array(times)\n",
    "    print(\n",
    "        f\"{name:>10}  mean={arr.mean():.1f} ms  std={arr.std():.1f} ms  fps={1000 / arr.mean():.1f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "positions = range(len(variant_names))\n",
    "means = [np.mean(speed_results[n]) for n in variant_names]\n",
    "stds = [np.std(speed_results[n]) for n in variant_names]\n",
    "\n",
    "bars = ax.bar(positions, means, yerr=stds, capsize=5, color=\"steelblue\", alpha=0.8)\n",
    "_ = ax.set_xticks(positions)\n",
    "_ = ax.set_xticklabels(\n",
    "    [f\"{n}\\n({v['params']})\" for n, v in zip(variant_names, MODEL_VARIANTS)]\n",
    ")\n",
    "_ = ax.set_ylabel(\"Inference Time (ms / frame)\")\n",
    "_ = ax.set_title(\"Inference Speed per Model Variant\")\n",
    "_ = ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Annotate FPS on bars\n",
    "for bar, m in zip(bars, means):\n",
    "    _ = ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 2,\n",
    "        f\"{1000 / m:.1f} fps\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"outputs/model_speed_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Count Sweep\n",
    "\n",
    "Run each model variant over N frames and plot the number of filtered detections per frame. A better model should give a stable count close to the expected number of visible players (~15-25 for a wide broadcast view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_counts = {name: [] for name in variant_names}\n",
    "\n",
    "for frame in bench_frames:\n",
    "    for name in variant_names:\n",
    "        dets = detectors[name].detect_and_filter(frame)\n",
    "        det_counts[name].append(len(dets))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "for name in variant_names:\n",
    "    _ = ax.plot(det_counts[name], label=name, alpha=0.8)\n",
    "\n",
    "_ = ax.set_xlabel(\"Frame\")\n",
    "_ = ax.set_ylabel(\"Detection Count (after filtering)\")\n",
    "_ = ax.set_title(f\"Detections per Frame by Model Variant  (conf={CONF_THRESHOLD})\")\n",
    "_ = ax.legend()\n",
    "_ = ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Distribution per Model\n",
    "\n",
    "Histogram of detection confidences on a single frame, overlaid for all variants. Larger models should push real-player confidences higher, making it easier to separate players from noise with a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this plot to a density plot using seaborn\n",
    "sample_frame = frames[SAMPLE_FRAME_INDICES[1]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "for name in variant_names:\n",
    "    # Use raw detections (before filtering) to see full confidence range\n",
    "    raw_dets = detectors[name].detect(sample_frame)\n",
    "    confs = [d[4] for d in raw_dets]\n",
    "    _ = ax.hist(\n",
    "        confs,\n",
    "        bins=25,\n",
    "        alpha=0.4,\n",
    "        label=f\"{name} ({len(confs)} dets)\",\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "\n",
    "_ = ax.axvline(\n",
    "    x=CONF_THRESHOLD,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"threshold={CONF_THRESHOLD}\",\n",
    ")\n",
    "_ = ax.set_xlabel(\"Confidence\")\n",
    "_ = ax.set_ylabel(\"Count\")\n",
    "_ = ax.set_title(f\"Detection Confidence Distribution — Frame {SAMPLE_FRAME_INDICES[1]}\")\n",
    "_ = ax.legend()\n",
    "_ = ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Confidence per Model\n",
    "\n",
    "Box plot of per-frame mean confidence across the sweep. Higher mean confidence with low variance indicates a model that is consistently sure about its detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_confs = {name: [] for name in variant_names}\n",
    "\n",
    "for frame in bench_frames:\n",
    "    for name in variant_names:\n",
    "        dets = detectors[name].detect_and_filter(frame)\n",
    "        if dets:\n",
    "            mean_confs[name].append(np.mean([d[4] for d in dets]))\n",
    "        else:\n",
    "            mean_confs[name].append(0.0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "data = [mean_confs[name] for name in variant_names]\n",
    "bp = ax.boxplot(data, labels=variant_names, patch_artist=True)\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(variant_names)))\n",
    "for patch, color in zip(bp[\"boxes\"], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax.set_ylabel(\"Mean Detection Confidence\")\n",
    "ax.set_title(\"Per-Frame Mean Confidence by Model Variant\")\n",
    "ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Aggregate table comparing all variants across key metrics: detection count (mean/std), mean confidence, and inference speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{'Model':>10} {'Params':>8} {'FLOPs(B)':>9} {'mAP':>6} {'Dets/fr':>8} {'Std':>6} \"\n",
    "    f\"{'Mean Conf':>10} {'ms/fr':>8} {'FPS':>8}\"\n",
    ")\n",
    "print(\"-\" * 88)\n",
    "\n",
    "for variant in MODEL_VARIANTS:\n",
    "    name = variant[\"name\"]\n",
    "    dc = np.array(det_counts[name])\n",
    "    mc = np.array(mean_confs[name])\n",
    "    sp = np.array(speed_results[name])\n",
    "    print(\n",
    "        f\"{name:>10} {variant['params']:>8} {variant['flops_b']:>9.1f} {variant['map']:>6.1f} \"\n",
    "        f\"{dc.mean():>8.1f} {dc.std():>6.1f} {mc.mean():>10.3f} \"\n",
    "        f\"{sp.mean():>8.1f} {1000 / sp.mean():>8.1f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed vs Accuracy Trade-off\n",
    "\n",
    "Scatter plot of mean inference time vs mean detection count. The ideal model sits in the bottom-right: high detection count (good recall) and low inference time (fast). The annotated Pareto front helps identify the best trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use seaborn for this plot\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "# Color YOLO26 differently from YOLOv8\n",
    "for variant in MODEL_VARIANTS:\n",
    "    name = variant[\"name\"]\n",
    "    x = np.mean(speed_results[name])\n",
    "    y = np.mean(det_counts[name])\n",
    "    is_yolo26 = name.startswith(\"yolo26\")\n",
    "    color = \"steelblue\" if is_yolo26 else \"tomato\"\n",
    "    _ = ax.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        s=variant[\"flops_b\"] * 1.5,\n",
    "        alpha=0.75,\n",
    "        zorder=5,\n",
    "        color=color,\n",
    "        label=\"YOLO26\"\n",
    "        if (is_yolo26 and name == \"yolo26n\")\n",
    "        else (\"YOLOv8 (legacy)\" if (not is_yolo26 and name == \"yolov8s\") else None),\n",
    "    )\n",
    "    _ = ax.annotate(\n",
    "        f\"{name}\\n({variant['params']}, mAP {variant['map']})\",\n",
    "        (x, y),\n",
    "        textcoords=\"offset points\",\n",
    "        xytext=(10, 5),\n",
    "        fontsize=8,\n",
    "    )\n",
    "\n",
    "_ = ax.set_xlabel(\"Mean Inference Time (ms / frame)\")\n",
    "_ = ax.set_ylabel(\"Mean Detections / Frame\")\n",
    "_ = ax.set_title(\"Speed vs Detection Count  (bubble size = FLOPs)\")\n",
    "_ = ax.legend()\n",
    "_ = ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Detections: What Do Larger Models Find That Smaller Ones Miss?\n",
    "\n",
    "Compare the smallest (nano) and largest (xlarge) model on a sample frame. Green boxes = both models agree. Blue boxes = only the larger model detects. Red boxes = only the smaller model detects. This highlights the recall gain from using a bigger backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box_a, box_b):\n",
    "    \"\"\"Compute IoU between two [x1,y1,x2,y2,...] boxes.\"\"\"\n",
    "    x1 = max(box_a[0], box_b[0])\n",
    "    y1 = max(box_a[1], box_b[1])\n",
    "    x2 = min(box_a[2], box_b[2])\n",
    "    y2 = min(box_a[3], box_b[3])\n",
    "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area_a = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])\n",
    "    area_b = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])\n",
    "    union = area_a + area_b - inter\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "def match_detections(dets_a, dets_b, iou_thresh=0.5):\n",
    "    \"\"\"Return (matched_a, matched_b, only_a, only_b).\"\"\"\n",
    "    matched_a, matched_b = set(), set()\n",
    "    for i, da in enumerate(dets_a):\n",
    "        for j, db in enumerate(dets_b):\n",
    "            if j not in matched_b and iou(da, db) >= iou_thresh:\n",
    "                matched_a.add(i)\n",
    "                matched_b.add(j)\n",
    "                break\n",
    "    only_a = [dets_a[i] for i in range(len(dets_a)) if i not in matched_a]\n",
    "    only_b = [dets_b[j] for j in range(len(dets_b)) if j not in matched_b]\n",
    "    common_a = [dets_a[i] for i in matched_a]\n",
    "    return common_a, only_a, only_b\n",
    "\n",
    "\n",
    "small_name = variant_names[0]  # nano\n",
    "large_name = variant_names[-1]  # xlarge\n",
    "\n",
    "for idx, frame in sorted(frames.items()):\n",
    "    dets_small = detectors[small_name].detect_and_filter(frame)\n",
    "    dets_large = detectors[large_name].detect_and_filter(frame)\n",
    "    common, only_small, only_large = match_detections(dets_small, dets_large)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    _ = ax.imshow(rgb)\n",
    "\n",
    "    for det in common:\n",
    "        x1, y1, x2, y2 = det[:4]\n",
    "        _ = ax.add_patch(\n",
    "            Rectangle((x1, y1), x2 - x1, y2 - y1, lw=2, ec=\"lime\", fc=\"none\")\n",
    "        )\n",
    "    for det in only_small:\n",
    "        x1, y1, x2, y2 = det[:4]\n",
    "        _ = ax.add_patch(\n",
    "            Rectangle((x1, y1), x2 - x1, y2 - y1, lw=2, ec=\"red\", fc=\"none\", ls=\"--\")\n",
    "        )\n",
    "    for det in only_large:\n",
    "        x1, y1, x2, y2 = det[:4]\n",
    "        _ = ax.add_patch(\n",
    "            Rectangle(\n",
    "                (x1, y1), x2 - x1, y2 - y1, lw=2, ec=\"dodgerblue\", fc=\"none\", ls=\"--\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    _ = ax.set_title(\n",
    "        f\"Frame {idx} — green=both ({len(common)})  \"\n",
    "        f\"red={small_name} only ({len(only_small)})  \"\n",
    "        f\"blue={large_name} only ({len(only_large)})\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "    _ = ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
